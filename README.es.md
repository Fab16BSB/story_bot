![License: MIT](https://img.shields.io/badge/Licence-MIT-green)
![University: Paris 8](https://img.shields.io/badge/University-Paris%208-red)
![deep: learning](https://img.shields.io/badge/deep-learning-blue)
![python: 3.12](https://img.shields.io/badge/python-3.12-brightgreen)
![Contributors](https://img.shields.io/badge/contributor-3-orange)
![Stars](https://img.shields.io/github/stars/Fab16BSB/image_classification?color=orange)
![Fork](https://img.shields.io/github/forks/Fab16BSB/image_classification?color=orange)
![Watchers](https://img.shields.io/github/watchers/Fab16BSB/image_classification?color=orange)

# Story Bot

## ğŸŒ Versiones MultilingÃ¼es del README

- ğŸ‡«ğŸ‡· [FrancÃ©s](./README.fr.md)
- ğŸ‡¬ğŸ‡§ [InglÃ©s](./README.md)
- ğŸ‡ªğŸ‡¸ [EspaÃ±ol (estÃ¡s aquÃ­)](#)

---

### ğŸ“˜ Resumen del Proyecto
Este proyecto, desarrollado por un equipo de tres como parte de nuestra MaestrÃ­a, tiene como objetivo crear un **chatbot capaz de responder preguntas en inglÃ©s sobre una historia**. Para ello, utilizamos el **conjunto de datos bAbI** de Facebook AI Research, diseÃ±ado para evaluar las capacidades de razonamiento de los modelos de aprendizaje automÃ¡tico.

El bot lee una historia, luego espera preguntas relacionadas e intenta responderlas de manera coherente. Se basa en un modelo de embedding entrenado directamente con el conjunto de datos.

---

## ğŸ“ Estructura del Proyecto

El proyecto estÃ¡ estructurado en varios directorios, cada uno con un rol especÃ­fico:

- **Code**: Contiene todos los scripts de Python, incluyendo la creaciÃ³n del modelo, su entrenamiento, la interfaz grÃ¡fica, asÃ­ como las funciones utilitarias necesarias para el funcionamiento del chatbot.

- **Data**: Agrupa los archivos del conjunto de datos utilizados para el entrenamiento y las pruebas, particularmente las historias, preguntas y respuestas del conjunto de datos bAbI.

- **Network**: Almacena el modelo entrenado, incluyendo tanto la arquitectura de la red como los pesos asociados.

---

## ğŸ“Š Conjuntos de Datos

El conjunto de datos **bAbI**, desarrollado por Facebook AI Research (FAIR), es una colecciÃ³n sintÃ©tica diseÃ±ada para probar las capacidades de razonamiento de los modelos de procesamiento del lenguaje natural.

Consiste en historias cortas seguidas de preguntas en inglÃ©s, cada una con una Ãºnica respuesta correcta. Cada ejemplo estÃ¡ estructurado en tres partes: un contexto (en forma de oraciones numeradas), una pregunta y la respuesta esperada.

El objetivo es permitir que un modelo aprenda a leer una historia, a razonar a travÃ©s de mÃºltiples oraciones y a responder correctamente una pregunta basÃ¡ndose Ãºnicamente en la informaciÃ³n relevante. Este conjunto de datos permite evaluar diversas habilidades como la comprensiÃ³n espacial o temporal, el razonamiento lÃ³gico y la gestiÃ³n de la memoria a corto plazo.

---

## âš™ï¸ Funcionamiento de una "Red de Memoria"

Una Red de Memoria es un modelo diseÃ±ado para resolver tareas de preguntas y respuestas sobre texto, simulando un proceso de razonamiento con memoria.

AquÃ­ tienes una explicaciÃ³n sencilla y progresiva de su funcionamiento:

### ğŸ§¾ Paso 1 - CodificaciÃ³n de la historia
La historia se convierte en vectores mediante una codificaciÃ³n de tipo **embedding**. Cada palabra (o frase) se convierte en un vector numÃ©rico. El modelo crea dos representaciones paralelas de esta memoria:
- una para comparar la memoria con la pregunta
- la otra para extraer una respuesta contextual

### â“ Paso 2 - CodificaciÃ³n de la pregunta
La pregunta se codifica por separado para que sea compatible con las representaciones de la historia.

### ğŸ¯ Paso 3 - CÃ¡lculo de la atenciÃ³n
El modelo compara la pregunta con cada elemento de la historia codificada para determinar las partes mÃ¡s relevantes. Esto se realiza mediante un **mecanismo de atenciÃ³n**, que asigna pesos a cada frase de la historia.

### ğŸ“š Paso 4 - RecuperaciÃ³n de la informaciÃ³n relevante
Los pesos de atenciÃ³n se utilizan para combinar las partes importantes de la memoria y formar una respuesta contextual. Esta respuesta se fusiona luego con la codificaciÃ³n de la pregunta.

### ğŸ” Paso 5 - Procesamiento secuencial con LSTM
La combinaciÃ³n de respuesta contextual + pregunta se pasa a una **LSTM**. Esta red secuencial permite razonar sobre la cronologÃ­a y las dependencias entre los elementos de la memoria.

### ğŸ—£ï¸ Paso 6 - PredicciÃ³n de la respuesta
La salida de la LSTM se proyecta en el espacio de las palabras conocidas (vocabulario), y luego se utiliza una funciÃ³n **softmax** para elegir la respuesta mÃ¡s probable.

### ğŸ“Œ Resultado
El modelo aprende a leer, comprender y razonar sobre textos cortos para responder de manera pertinente a preguntas formuladas en inglÃ©s.

---

## ğŸ§± Arquitectura del modelo

AquÃ­ tienes el esquema de la arquitectura de nuestro modelo, ilustrando el flujo de datos a travÃ©s de las diferentes capas:

![Diagrama de la Arquitectura del modelo](Result/architecture.png)

---

## ğŸ’» TecnologÃ­as Utilizadas

* **Lenguaje:** Python 3.10+
* **LibrerÃ­as:** Keras
* **GUI:** Tkinter

---

## ğŸš€ Ejecutar el Proyecto

Para iniciar este proyecto y utilizar los modelos de clasificaciÃ³n de imÃ¡genes, sigue estos pasos:

1.  Clona el repositorio:
    ```bash
    git clone [https://github.com/Fab16BSB/story_bot.git](https://github.com/Fab16BSB/story_bot.git)
    ```

2.  Instala las dependencias:
    ```bash
    cd story_bot
    pip install -r requirements.txt
    ```

3.  Ejecuta el cÃ³digo:
    ```bash
    cd Code
    python Main.py
    ```

---

## ğŸ–¥ï¸ Interfaz GrÃ¡fica con Tkinter

La interfaz de usuario estÃ¡ construida con **Tkinter**, un mÃ³dulo estÃ¡ndar de Python para el desarrollo de interfaces grÃ¡ficas. Incluye:

* Un Ã¡rea para mostrar la historia.
* Un Ã¡rea para mostrar la pregunta actual.
* Un campo para introducir una respuesta manual o consultar la generada.
* Botones para interactuar con el bot o cambiar de escenario.

![interface](Result/interface.png)

---

## ğŸ§ª Resultados

Estos ejemplos ilustran la capacidad del modelo para comprender un relato corto, razonar sobre su contenido y proporcionar respuestas coherentes dentro de las tareas propuestas por el conjunto de datos bAbI.

![why question](Result/demo.png)

![where question](Result/demo2.png)

![what question](Result/demo3.png)

![single word generate](Result/demo4.png)

---

## âš ï¸ Limitaciones

* El modelo estÃ¡ restringido al vocabulario presente en el conjunto de datos; no reconoce palabras que no figuren en Ã©l.
* El chatbot solo funciona en inglÃ©s; no se admite ningÃºn otro idioma.
* El sistema no maneja ambigÃ¼edades ni interpretaciones complejas fuera de los escenarios previstos en el conjunto de datos.
* Las respuestas generadas se limitan a una sola palabra, lo que restringe la riqueza de las interacciones posibles.

---

## ğŸ§‘â€ğŸ’» Autores

* Zeineb Ghrib
* Nadia Essfini

---

## ğŸ“š Fuentes

Nuestro proyecto se basa principalmente en los siguientes recursos:

ğŸ“„ ArtÃ­culo de referencia: *End-To-End Memory Networks* â€” [Consultar en arXiv](https://arxiv.org/pdf/1503.08895.pdf)

ğŸ“¦ Conjunto de datos utilizado: *bAbI dataset* â€” [Disponible en Kaggle](https://www.kaggle.com/datasets/roblexnana/the-babi-tasks-for-nlp-qa-system)
