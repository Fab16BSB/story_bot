![License: MIT](https://img.shields.io/badge/Licence-MIT-green)
![University: Paris 8](https://img.shields.io/badge/University-Paris%208-red)
![deep: learning](https://img.shields.io/badge/deep-learning-blue)
![python: 3.12](https://img.shields.io/badge/python-3.12-brightgreen)
![Contributors](https://img.shields.io/badge/contributor-3-orange)
![Stars](https://img.shields.io/github/stars/Fab16BSB/image_classification?color=orange)
![Fork](https://img.shields.io/github/forks/Fab16BSB/image_classification?color=orange)
![Watchers](https://img.shields.io/github/watchers/Fab16BSB/image_classification?color=orange)

# Story Bot

## ğŸŒ Versions multilingues du README

- ğŸ‡«ğŸ‡· [FranÃ§ais (vous Ãªtes ici)](#)
- ğŸ‡¬ğŸ‡§ [English](./README.md)
- ğŸ‡ªğŸ‡¸ [EspaÃ±ol](./README.es.md)

---

## ğŸ“˜ AperÃ§u du Projet

Ce projet, rÃ©alisÃ© en trinÃ´me dans le cadre de notre Master, vise Ã  dÃ©velopper un **chatbot capable de rÃ©pondre Ã  des 
questions en anglais sur une histoire**. Nous utilisons pour cela le **[jeu de donnÃ©es bAbI](https://www.kaggle.com/datasets/roblexnana/the-babi-tasks-for-nlp-qa-system)** 
de Facebook AI Research, conÃ§u pour Ã©valuer les capacitÃ©s de raisonnement des modÃ¨les d'apprentissage automatique.

Le bot lit une histoire, puis attend des questions en lien avec celle-ci, et tente d'y rÃ©pondre avec cohÃ©rence. Il sâ€™appuie sur un modÃ¨le dâ€™embedding entraÃ®nÃ© directement sur le dataset.

---

## ğŸ“ Structure du Projet

Le projet est structurÃ© en plusieurs rÃ©pertoires, chacun ayant un rÃ´le spÃ©cifique :


- **Code** : Contient lâ€™ensemble des scripts Python, incluant la crÃ©ation du modÃ¨le, son entraÃ®nement, lâ€™interface graphique, ainsi que les fonctions utilitaires nÃ©cessaires au fonctionnement du chatbot.


- **Data** : Regroupe les fichiers du jeu de donnÃ©es utilisÃ© pour lâ€™entraÃ®nement et les tests, notamment les histoires, questions et rÃ©ponses issues du dataset bAbI.


- **Network** : Stocke le modÃ¨le entraÃ®nÃ©, incluant Ã  la fois lâ€™architecture du rÃ©seau et les poids associÃ©s.

---

## ğŸ“Š Datasets
Le jeu de donnÃ©es **bAbI**, dÃ©veloppÃ© par Facebook AI Research (FAIR), est un ensemble synthÃ©tique conÃ§u pour tester les capacitÃ©s de raisonnement des modÃ¨les de traitement du langage naturel. 

Il se compose dâ€™histoires courtes suivies de questions en anglais, avec une rÃ©ponse unique Ã  chaque fois. Chaque exemple est structurÃ© en trois parties : un contexte (sous forme de phrases numÃ©rotÃ©es), une question, et la rÃ©ponse attendue. 

Lâ€™objectif est de permettre Ã  un modÃ¨le dâ€™apprendre Ã  lire une histoire, Ã  raisonner sur plusieurs phrases et Ã  rÃ©pondre correctement Ã  une question en sâ€™appuyant uniquement sur les informations pertinentes. Ce dataset permet dâ€™Ã©valuer diffÃ©rentes compÃ©tences telles que la comprÃ©hension spatiale ou temporelle, le raisonnement logique et la gestion de la mÃ©moire Ã  court terme. 

---

## âš™ï¸ Fonctionnement d'un "Memory Network"

Un Memory Network est un modÃ¨le conÃ§u pour rÃ©soudre des tÃ¢ches de question-rÃ©ponse sur du texte en simulant un processus de raisonnement avec mÃ©moire.

Voici une explication simple et progressive de son fonctionnement :

### ğŸ§¾ Ã‰tape 1 - Encodage de lâ€™histoire  
Lâ€™histoire est convertie en vecteurs via un encodage de type *embedding*. Chaque mot (ou phrase) devient un vecteur numÃ©rique. Le modÃ¨le crÃ©e deux reprÃ©sentations parallÃ¨les de cette mÃ©moire :  
- l'une pour comparer la mÃ©moire avec la question  
- l'autre pour extraire une rÃ©ponse contextuelle  

### â“ Ã‰tape 2 - Encodage de la question  
La question est encodÃ©e sÃ©parÃ©ment pour Ãªtre compatible avec les reprÃ©sentations de lâ€™histoire.

### ğŸ¯ Ã‰tape 3 - Calcul de lâ€™attention  
Le modÃ¨le compare la question Ã  chaque Ã©lÃ©ment de lâ€™histoire encodÃ©e pour dÃ©terminer les parties les plus pertinentes. Cela se fait via un mÃ©canisme dâ€™attention, qui attribue des poids Ã  chaque phrase de lâ€™histoire.

### ğŸ“š Ã‰tape 4 - RÃ©cupÃ©ration des informations pertinentes  
Les poids dâ€™attention sont utilisÃ©s pour combiner les parties importantes de la mÃ©moire afin de former une rÃ©ponse contextuelle. Cette rÃ©ponse est ensuite fusionnÃ©e avec lâ€™encodage de la question.

### ğŸ” Ã‰tape 5 - Traitement sÃ©quentiel avec LSTM  
La combinaison rÃ©ponse contextuelle + question est passÃ©e dans une LSTM. Ce rÃ©seau sÃ©quentiel permet de raisonner sur la chronologie et les dÃ©pendances entre les Ã©lÃ©ments de la mÃ©moire.

### ğŸ—£ï¸ Ã‰tape 6 - PrÃ©diction de la rÃ©ponse  
La sortie de la LSTM est projetÃ©e dans lâ€™espace des mots connus (vocabulaire), puis une softmax est utilisÃ©e pour choisir la rÃ©ponse la plus probable.

### ğŸ“Œ RÃ©sultat 
Le modÃ¨le apprend Ã  lire, comprendre et raisonner sur des textes courts pour rÃ©pondre de faÃ§on pertinente Ã  des questions posÃ©es en anglais.

---

## ğŸ§± Architecture du modÃ¨le 

Voici le schÃ©ma de l'architecture de notre modÃ¨le, illustrant le flux des donnÃ©es Ã  travers les diffÃ©rentes couches :

![SchÃ©ma de l'Architecture du modele](Result/architecture.png)

---

## ğŸ’» Technologies UtilisÃ©es

* **Langage:** Python 3.10+
* **Librairies:** Keras
* **GUI** Tkinter
---

## ğŸš€ ExÃ©cuter le Projet
Pour lancer ce projet et utiliser les modÃ¨les de classification d'images, suivez ces Ã©tapes :

1. Cloner le dÃ©pÃ´t :
```
git clone https://github.com/Fab16BSB/story_bot.git
```

2. Installer les dÃ©pendances :
```
cd story_bot
pip install -r requirements.txt
```

3. ExÃ©cuter le code :
```
cd Code
python Main.py
```
---

## ğŸ–¥ï¸ Interface Graphique avec Tkinter

Lâ€™interface utilisateur est construite avec **Tkinter**, un module standard de Python pour le dÃ©veloppement dâ€™interfaces graphiques. Elle comprend :

- Une zone pour afficher lâ€™histoire.
- Une zone pour afficher la question actuelle.
- Un champ pour saisir une rÃ©ponse manuelle ou consulter celle gÃ©nÃ©rÃ©e.
- Des boutons pour interagir avec le bot ou changer de scÃ©nario.

![interface](Result/interface.png)

---

## ğŸ§ª RÃ©sultats
Ces exemples illustrent la capacitÃ© du modÃ¨le Ã  comprendre un court rÃ©cit, raisonner sur son contenu et fournir des rÃ©ponses cohÃ©rentes dans le cadre des tÃ¢ches proposÃ©es par le dataset bAbI.

![why question](Result/demo.png)

![where question](Result/demo2.png)

![what question](Result/demo3.png)

![sigle word generate](Result/demo4.png)

---

## âš ï¸ Limitations

- Le modÃ¨le est restreint au vocabulaire prÃ©sent dans le jeu de donnÃ©es : il ne reconnaÃ®t pas les mots qui n'y figurent pas.


- Le chatbot fonctionne uniquement en anglais ; aucune autre langue nâ€™est prise en charge.


- Le systÃ¨me ne traite pas les ambiguÃ¯tÃ©s ni les interprÃ©tations complexes en dehors des scÃ©narios prÃ©vus dans le dataset.


- Les rÃ©ponses gÃ©nÃ©rÃ©es se limitent Ã  un seul mot, ce qui restreint la richesse des interactions possibles.

---

## ğŸ§‘â€ğŸ’» Authors

- Zeineb Ghrib
- Nadia Essfini

---


## ğŸ“š Sources

Notre projet sâ€™appuie principalement sur les ressources suivantes :

ğŸ“„ Article de rÃ©fÃ©rence : *End-To-End Memory Networks* â€” [Consulter sur arXiv](https://arxiv.org/pdf/1503.08895.pdf)

ğŸ“¦ Jeu de donnÃ©es utilisÃ© : *bAbI dataset* â€” [Disponible sur Kaggle](https://www.kaggle.com/datasets/roblexnana/the-babi-tasks-for-nlp-qa-system)
